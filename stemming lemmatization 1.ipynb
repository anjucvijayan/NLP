{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming amd lemmatization are methods used by searchengines and chatbots to analyse the meaning behind the word\n",
    "# stemming uses to stem of the word ,while lemmatization uses the context in which the word is being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b907d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #natural language toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ef6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547c72cc",
   "metadata": {},
   "source": [
    "# Porterstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80518dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7cf12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run---->run\n",
      "ran---->ran\n",
      "write---->write\n",
      "wrote---->wrote\n",
      "written---->written\n",
      "mostly---->mostli\n"
     ]
    }
   ],
   "source": [
    "words=['run','ran','write','wrote','written','mostly']\n",
    "for word in words:\n",
    "    print(word+'---->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f940f3",
   "metadata": {},
   "source": [
    "# Snowballstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f1626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995d1101",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stem=SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8d1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['haai','hellow','bie','nicely','badly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7136097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haai ---> haai\n",
      "hellow ---> hellow\n",
      "bie ---> bie\n",
      "nicely ---> nice\n",
      "badly ---> bad\n"
     ]
    }
   ],
   "source": [
    "#snowball stemmer\n",
    "for word in words:\n",
    "    print(word,'--->',s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5302c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haai ---> haai\n",
      "hellow ---> hellow\n",
      "bie ---> bie\n",
      "nicely ---> nice\n",
      "badly ---> badli\n"
     ]
    }
   ],
   "source": [
    "#porter stemmer\n",
    "for word in words:\n",
    "    print(word,'--->',p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d2a0e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fairli\n",
      "fair\n"
     ]
    }
   ],
   "source": [
    "print(p_stemmer.stem('fairly'))\n",
    "print(s_stem.stem('fairly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa38cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['intelligently','couragiously','living','godthings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af1d382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intelligently ---> intellig\n",
      "couragiously ---> couragi\n",
      "living ---> live\n",
      "godthings ---> godth\n",
      "---------------------\n",
      "intelligently ----> intellig\n",
      "couragiously ----> couragi\n",
      "living ----> live\n",
      "godthings ----> godth\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,'--->',s_stem.stem(word))\n",
    "print('---------------------')\n",
    "for word in words:\n",
    "    print(word,'---->',p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5465d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i -----> i\n",
      "am -----> am\n",
      "meeting -----> meet\n",
      "him -----> him\n",
      "tommorrow -----> tommorrow\n",
      "in -----> in\n",
      "the -----> the\n",
      "meeting -----> meet\n",
      "-----------------------\n",
      "i -----> i\n",
      "am -----> am\n",
      "meeting -----> meet\n",
      "him -----> him\n",
      "tommorrow -----> tommorrow\n",
      "in -----> in\n",
      "the -----> the\n",
      "meeting -----> meet\n"
     ]
    }
   ],
   "source": [
    "pharse='i am meeting him tommorrow in the meeting'\n",
    "for word in pharse.split():\n",
    "    print(word,'----->',p_stemmer.stem(word))\n",
    "print('-----------------------')\n",
    "for word in pharse.split():\n",
    "    print(word,'----->',s_stem.stem(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef9cb457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you -----> you\n",
      "should -----> should\n",
      "better -----> better\n",
      "keep -----> keep\n",
      "quiet -----> quiet\n",
      "-----------------------\n",
      "you -----> you\n",
      "should -----> should\n",
      "better -----> better\n",
      "keep -----> keep\n",
      "quiet -----> quiet\n"
     ]
    }
   ],
   "source": [
    "pharse='you should better keep quiet'\n",
    "for word in pharse.split():\n",
    "    print(word,'----->',p_stemmer.stem(word))\n",
    "print('-----------------------')\n",
    "for word in pharse.split():\n",
    "    print(word,'----->',s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91025cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i -----> i\n",
      "saw -----> saw\n",
      "him -----> him\n",
      "yesterday, -----> yesterday,\n",
      "he -----> he\n",
      "was -----> wa\n",
      "walking -----> walk\n",
      "down -----> down\n",
      "the -----> the\n",
      "street -----> street\n",
      "with -----> with\n",
      "his -----> hi\n",
      "friend -----> friend\n",
      "-----------------------\n",
      "i -----> i\n",
      "saw -----> saw\n",
      "him -----> him\n",
      "yesterday, -----> yesterday,\n",
      "he -----> he\n",
      "was -----> was\n",
      "walking -----> walk\n",
      "down -----> down\n",
      "the -----> the\n",
      "street -----> street\n",
      "with -----> with\n",
      "his -----> his\n",
      "friend -----> friend\n"
     ]
    }
   ],
   "source": [
    "pharse='i saw him yesterday, he was walking down the street with his friend'\n",
    "for word in pharse.split():\n",
    "    print(word,'----->',p_stemmer.stem(word))\n",
    "print('-----------------------')\n",
    "for word in pharse.split():\n",
    "    print(word,'----->',s_stem.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d09fd",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "587371fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d90105a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john \t john\n",
      "adam \t adam\n",
      "is \t be\n",
      "one \t one\n",
      "of \t of\n",
      "the \t the\n",
      "researcher \t researcher\n",
      "who \t who\n",
      "invented \t invent\n",
      "the \t the\n",
      "direction \t direction\n",
      "of \t of\n",
      "way \t way\n",
      "towards \t towards\n",
      "success \t success\n",
      "! \t !\n"
     ]
    }
   ],
   "source": [
    "txt1=nlp('john adam is one of the researcher who invented the direction of way towards success!')\n",
    "for token in txt1:\n",
    "    print(token.text,'\\t',token.lemma_)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf5b9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to get lemmatization\n",
    "def show_lemmas(text):\n",
    "    for t in text:\n",
    "        print(f'{t.text:{12}} {t.lemma_:{6}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a78c4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you          you   \n",
      "should       should\n",
      "better       well  \n",
      "keep         keep  \n",
      "quit         quit  \n"
     ]
    }
   ],
   "source": [
    "phrase=nlp('you should better keep quit')\n",
    "show_lemmas(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93f036b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i            I     \n",
      "am           be    \n",
      "going        go    \n",
      "to           to    \n",
      "fishing      fishing\n"
     ]
    }
   ],
   "source": [
    "phrase=nlp('i am going to fishing')\n",
    "show_lemmas(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daa2ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this         this  \n",
      "might        might \n",
      "be           be    \n",
      "going        go    \n",
      "to           to    \n",
      "a            a     \n",
      "huge         huge  \n",
      "breakthrough breakthrough\n",
      "in           in    \n",
      "the          the   \n",
      "field        field \n",
      "of           of    \n",
      "Artificial   Artificial\n",
      "Intelligence Intelligence\n"
     ]
    }
   ],
   "source": [
    "phrase=nlp('this might be going to a huge breakthrough in the field of Artificial Intelligence')\n",
    "show_lemmas(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4406bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john         john  \n",
      "adam         adam  \n",
      "is           be    \n",
      "one          one   \n",
      "researcher   researcher\n",
      "who          who   \n",
      "invent       invent\n",
      "the          the   \n",
      "direction    direction\n",
      "of           of    \n",
      "way          way   \n",
      "towards      towards\n",
      "success      success\n",
      "!            !     \n"
     ]
    }
   ],
   "source": [
    "phrase=nlp('john adam is one researcher who invent the direction of way towards success!')\n",
    "show_lemmas(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "399ade4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i            I     \n",
      "am           be    \n",
      "meeting      meet  \n",
      "him          he    \n",
      "tomorrow.our tomorrow.our\n",
      "meet         meet  \n",
      "is           be    \n",
      "confidential confidential\n"
     ]
    }
   ],
   "source": [
    "txt3=nlp(u'i am meeting him tomorrow.our meet is confidential')\n",
    "show_lemmas(txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "304a988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hats         hat   \n",
      "off          off   \n",
      "to           to    \n",
      "such         such  \n",
      "a            a     \n",
      "great        great \n",
      "person       person\n"
     ]
    }
   ],
   "source": [
    "txt3=nlp('hats off to such a great person')\n",
    "show_lemmas(txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88192c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
